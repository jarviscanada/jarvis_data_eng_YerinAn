{
  "metadata": {
    "name": "Spark Dataframe - WDI Data Analytics",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# SparkSession\n\nSparkSession is automatically created when you start up a Notebook (e.g. Zeppelin, Databricks)\n\n\u003cimg src\u003d\"https://i.imgur.com/5Ai45fb.jpg\" width\u003d500px\u003e"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n//Scala SparkSession\nspark"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\nspark-submit --version"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n\n# Show DataFrame\n\n`df.show()` is the Spark native API that displays data but it\u0027s not pretty. \n\n`z.show(df)` is a Zeppelin build-in feature that allows you to show a df result in a pretty way"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n// List all hive tables in a df\nval tables_df \u003d spark.sql(\"show tables\")"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\ntables_df.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nz.show(tables_df)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n\n# Spark SQL vs Dataframe\n\n`%sql` is the Spark SQL interpreter\n\n`%spark.pyspark` is the PySpark interpreter\n\n`%spark` is the Spark Scala interpreter"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n\nselect count(1) from wdi_csv_parquet"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n\nvar wdi_df \u003d spark.sql(\"SELECT * from wdi_csv_parquet\")\nwdi_df.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nwdi_df.printSchema()\nz.show(wdi_df)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n\n# Show Historical GDP for Canada\n\n- Re-write the hive query (left cell) using PySpark df"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\nSELECT year, IndicatorValue as GDP\nFROM wdi_csv_parquet\nWHERE indicatorCode \u003d \u0027NY.GDP.MKTP.KD.ZG\u0027 and countryName \u003d \u0027Canada\u0027\nORDER BY year\n"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nval wdi_canada_df \u003d wdi_df.filter($\"IndicatorCode\" \u003d\u003d\u003d \"NY.GDP.MKTP.KD.ZG\")\n                    .filter($\"countryName\" \u003d\u003d\u003d \"Canada\")\n                    \nz.show(wdi_canada_df.selectExpr(\"year\", \"IndicatorValue\").sort($\"year\"))"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n\n# Show GDP for Each County and Sort By Year\n\n- Re-write the hive query (left cell) using PySpark df  \n    - hint: you can create multiple DFs "
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\nSELECT countryname,\n       year,\n       indicatorcode,\n       indicatorvalue\nFROM wdi_csv_parquet\nWHERE indicatorcode \u003d \u0027NY.GDP.MKTP.KD.ZG\u0027\nDISTRIBUTE BY countryname\nSORT BY countryname, year\n"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n\nval gdp_country_df \u003d wdi_df.repartition($\"countryName\")\n                    .filter($\"IndicatorCode\" \u003d\u003d\u003d \"NY.GDP.MKTP.KD.ZG\")\n                    .sort(\"countryName\", \"year\")\n                    \nz.show(gdp_country_df.selectExpr(\"countryName\", \"year\", \"indicatorCode\", \"indicatorValue\"))"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Find the highest GDP for each country\n\n- Re-write the hive query (left cell) using PySpark df\n"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n\nSELECT wdi_csv_parquet.indicatorvalue AS value, \n       wdi_csv_parquet.year           AS year, \n       wdi_csv_parquet.countryname    AS country \nFROM   (SELECT Max(indicatorvalue) AS ind, \n               countryname \n        FROM   wdi_csv_parquet \n        WHERE  indicatorcode \u003d \u0027NY.GDP.MKTP.KD.ZG\u0027 \n               AND indicatorvalue \u003c\u003e 0 \n        GROUP  BY countryname) t1 \n       INNER JOIN wdi_csv_parquet \n               ON t1.ind \u003d wdi_csv_parquet.indicatorvalue \n                  AND t1.countryname \u003d wdi_csv_parquet.countryname\n"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n\nval max_gdp_country_df \u003d wdi_df.filter($\"indicatorcode\" \u003d\u003d\u003d \"NY.GDP.MKTP.KD.ZG\" )\n                        .filter($\"indicatorvalue\" \u003d!\u003d 0)\n                        .groupBy(\"countryName\").agg(expr(\"max(indicatorValue) as maxValue\"))\n\nmax_gdp_country_df.show(5)\n                        \nvar find_gdp_df \u003d max_gdp_country_df.as(\"m_gdp\")\n                .join(wdi_df.as(\"wdi\"),\n                $\"m_gdp.maxValue\" \u003c\u003d\u003e $\"wdi.indicatorValue\"\n                \u0026\u0026 $\"m_gdp.countryName\" \u003c\u003d\u003e $\"wdi.countryName\", \"inner\")\n                \nz.show(find_gdp_df.selectExpr(\"wdi.IndicatorValue\", \"wdi.year\", \"wdi.countryName\"))"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n"
    }
  ]
}